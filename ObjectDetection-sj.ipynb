{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1420c7e-9ef3-4bf7-a0fc-a7c357c3bff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using TensorFlow version: 2.10.1\n",
      "Found 7357 images belonging to 102 classes.\n",
      "Found 1788 images belonging to 102 classes.\n",
      "Found 102 classes (subfolders) in 'LP-IV-datasets\\Object Detection(Ass6)\\caltech-101-img'.\n",
      "\n",
      "--- a. Loading pre-trained VGG16 model ---\n",
      "Model and custom weights loaded successfully.\n",
      "\n",
      "--- b. Freezing base model layers ---\n",
      "\n",
      "--- c. Adding new custom classifier ---\n",
      "New model created with VGG16 base and custom head.\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
      "                                                                 \n",
      " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
      "                                                                 \n",
      " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
      "                                                                 \n",
      " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
      "                                                                 \n",
      " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
      "                                                                 \n",
      " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
      "                                                                 \n",
      " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
      "                                                                 \n",
      " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
      "                                                                 \n",
      " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
      "                                                                 \n",
      " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
      "                                                                 \n",
      " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
      "                                                                 \n",
      " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
      "                                                                 \n",
      " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
      "                                                                 \n",
      " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 25088)             0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 512)               12845568  \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 512)               0         \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 102)               52326     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 27,612,582\n",
      "Trainable params: 12,897,894\n",
      "Non-trainable params: 14,714,688\n",
      "_________________________________________________________________\n",
      "\n",
      "--- d. Training the custom classifier (Phase 1) ---\n",
      "Epoch 1/10\n",
      " 34/230 [===>..........................] - ETA: 22:34 - loss: 3.9475 - accuracy: 0.2279"
     ]
    }
   ],
   "source": [
    "# PS-9, PS-10, PS-11, PS-16 : Object Detection \n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os\n",
    "\n",
    "print(f\"Using TensorFlow version: {tf.__version__}\")\n",
    "\n",
    "# --- Setup: Define Paths and Image Parameters ---\n",
    "IMG_WIDTH, IMG_HEIGHT = 224, 224 # VGG16 standard size\n",
    "BATCH_SIZE = 32\n",
    "DATA_DIR = r\"LP-IV-datasets\\Object Detection(Ass6)\\caltech-101-img\"\n",
    "WEIGHTS_PATH = r\"LP-IV-datasets\\Object Detection(Ass6)\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "# Check if files exist\n",
    "if not os.path.exists(DATA_DIR):\n",
    "    print(f\"Error: Dataset folder '{DATA_DIR}' not found.\")\n",
    "    exit()\n",
    "if not os.path.exists(WEIGHTS_PATH):\n",
    "    print(f\"Error: Weights file '{WEIGHTS_PATH}' not found.\")\n",
    "    exit()\n",
    "\n",
    "# --- Setup: Load and Preprocess Data ---\n",
    "# We use ImageDataGenerator to load from folders.\n",
    "# We also split the data into 80% training and 20% validation.\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,            # Normalize pixel values\n",
    "    validation_split=0.2,      # Hold back 20% for validation\n",
    "    shear_range=0.2,           # Add some data augmentation\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True\n",
    ")\n",
    "\n",
    "# Training data generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training' # Set as training data\n",
    ")\n",
    "\n",
    "# Validation data generator\n",
    "validation_generator = train_datagen.flow_from_directory(\n",
    "    DATA_DIR,\n",
    "    target_size=(IMG_WIDTH, IMG_HEIGHT),\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation' # Set as validation data\n",
    ")\n",
    "\n",
    "# Get the number of classes (subfolders)\n",
    "num_classes = train_generator.num_classes\n",
    "print(f\"Found {num_classes} classes (subfolders) in '{DATA_DIR}'.\")\n",
    "\n",
    "# --- a. Load in a pre-trained CNN model ---\n",
    "print(\"\\n--- a. Loading pre-trained VGG16 model ---\")\n",
    "# 1. Initialize VGG16 with the correct input shape\n",
    "#    We set 'weights=None' because we will load them from your file\n",
    "base_model = VGG16(\n",
    "    weights=None, \n",
    "    include_top=False, # Do not include the final classifier\n",
    "    input_shape=(IMG_WIDTH, IMG_HEIGHT, 3)\n",
    ")\n",
    "\n",
    "# 2. Load the weights from your specific file\n",
    "base_model.load_weights(WEIGHTS_PATH)\n",
    "print(\"Model and custom weights loaded successfully.\")\n",
    "\n",
    "\n",
    "# --- b. Freeze parameters in lower convolutional layers ---\n",
    "print(\"\\n--- b. Freezing base model layers ---\")\n",
    "# We freeze all layers in the base model so we only train our new classifier\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "\n",
    "# --- c. Add custom classifier ---\n",
    "print(\"\\n--- c. Adding new custom classifier ---\")\n",
    "# 1. Get the output of the base model\n",
    "x = base_model.output\n",
    "\n",
    "# 2. Add our new layers\n",
    "x = Flatten()(x) # Flatten the 3D features to 1D\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x) # Dropout for regularization\n",
    "predictions = Dense(num_classes, activation='softmax')(x) # Output layer\n",
    "\n",
    "# 3. Create the final model\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "print(\"New model created with VGG16 base and custom head.\")\n",
    "model.summary()\n",
    "\n",
    "\n",
    "# --- d. Train classifier layers on training data ---\n",
    "print(\"\\n--- d. Training the custom classifier (Phase 1) ---\")\n",
    "# Compile the model for the first round of training\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4), # Use Adam with a moderate learning rate\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Train the model (e.g., for 10 epochs)\n",
    "# We only train the new Dense/Dropout layers\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=10,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "\n",
    "# --- e. Fine-tune hyperparameters and unfreeze layers ---\n",
    "print(\"\\n--- e. Fine-tuning the model (Phase 2) ---\")\n",
    "# Now we unfreeze the top block of VGG16 (block5) to fine-tune it\n",
    "print(\"Unfreezing 'block5' of VGG16...\")\n",
    "for layer in base_model.layers:\n",
    "    if layer.name.startswith('block5'):\n",
    "        layer.trainable = True\n",
    "\n",
    "# Re-compile the model with a VERY low learning rate for fine-tuning\n",
    "# This prevents destroying the learned weights\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-5), # Must be very low!\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Continue training (fine-tuning) for 10 more epochs\n",
    "history_fine_tune = model.fit(\n",
    "    train_generator,\n",
    "    epochs=20, # Continue from epoch 10 to 20\n",
    "    initial_epoch=history.epochs, # Start where we left off\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "print(\"\\n--- Model training complete ---\")\n",
    "\n",
    "# Evaluate the final model\n",
    "print(\"\\nFinal Model Evaluation:\")\n",
    "final_loss, final_accuracy = model.evaluate(validation_generator)\n",
    "print(f\"Final Validation Loss: {final_loss:.4f}\")\n",
    "print(f\"Final Validation Accuracy: {final_accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5cc764-4e76-41f9-a47b-6dbdbd935128",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
